from base_crawler import BaseCrawler
from selenium.webdriver.common.by import By

class XPathCrawler(BaseCrawler):
    def crawl(self, xpath):
        try:
            element = self.driver.find_element(By.XPATH, xpath)
            href = element.get_attribute("href")
            if href:
                print(f"Found file at XPath: {href}")
                self.download_file(href)
            else:
                print("No href found at provided XPath.")
        except Exception as e:
            print(f"XPath error: {e}")

_________________________________________________________________
from base_crawler import BaseCrawler
from selenium.webdriver.common.by import By

class ExtensionCrawler(BaseCrawler):
    def crawl(self, extension=".pdf"):
        links = self.driver.find_elements(By.TAG_NAME, "a")
        for link in links:
            href = link.get_attribute("href")
            if href and href.lower().endswith(extension):
                print(f"Found file with extension: {href}")
                self.download_file(href)
                break
________________________________________________________________
from base_crawler import BaseCrawler
from selenium.webdriver.common.by import By

class KeywordCrawler(BaseCrawler):
    def crawl(self, keyword):
        keyword = keyword.lower()
        links = self.driver.find_elements(By.TAG_NAME, "a")
        for link in links:
            text = link.text.lower()
            href = link.get_attribute("href")
            if keyword in text and href:
                print(f"Found file with keyword: {href}")
                self.download_file(href)
                break
_________________________________________________________________
from selenium import webdriver
import os
import time
import requests

class BaseCrawler:
    def __init__(self, url, download_dir="downloads"):
        self.url = url
        self.download_dir = os.path.abspath(download_dir)
        os.makedirs(self.download_dir, exist_ok=True)

        chrome_options = webdriver.ChromeOptions()
        chrome_options.add_argument("--headless")
        self.driver = webdriver.Chrome(options=chrome_options)
        self.driver.get(self.url)
        time.sleep(3)

    def download_file(self, href):
        try:
            filename = os.path.join(self.download_dir, href.split("/")[-1])
            response = requests.get(href)
            with open(filename, "wb") as f:
                f.write(response.content)
            print(f"Downloaded: {filename}")
        except Exception as e:
            print(f"Failed to download {href}: {e}")

    def close(self):
        self.driver.quit()
__________________________________________________________________________
main.py
-------

from xpath_crawler import XPathCrawler
from extension_crawler import ExtensionCrawler
from keyword_crawler import KeywordCrawler

def run_crawler(mode, url, param):
    crawler = None
    try:
        if mode == "xpath":
            crawler = XPathCrawler(url)
            crawler.crawl(param)
        elif mode == "extension":
            crawler = ExtensionCrawler(url)
            crawler.crawl(param)
        elif mode == "keyword":
            crawler = KeywordCrawler(url)
            crawler.crawl(param)
        else:
            print("Invalid mode. Use: xpath | extension | keyword")
    finally:
        if crawler:
            crawler.close()

# Example usage:
# run_crawler("xpath", "https://example.com", "//a[contains(text(), 'Annual Report')]")
# run_crawler("extension", "https://example.com", ".pdf")
# run_crawler("keyword", "https://example.com", "2024 annual report")
____________________________________________________________________________________
