from selenium.webdriver.common.by import By

class XPathCrawler:
    def __init__(self, driver):
        self.driver = driver

    def crawl(self, param, download_file):
        try:
            element = self.driver.find_element(By.XPATH, param)
            href = element.get_attribute("href")
            if href:
                print(f"[XPath] Found: {href}")
                download_file(href)
            else:
                print("No href found at provided XPath.")
        except Exception as e:
            print(f"[XPath] Error: {e}")

_________________________________________________________________
from selenium.webdriver.common.by import By

class ExtensionCrawler:
    def __init__(self, driver):
        self.driver = driver

    def crawl(self, param, download_file):
        links = self.driver.find_elements(By.TAG_NAME, "a")
        for link in links:
            href = link.get_attribute("href")
            if href and href.lower().endswith(param):
                print(f"[Extension] Found: {href}")
                download_file(href)
                break
________________________________________________________________
from selenium.webdriver.common.by import By

class KeywordCrawler:
    def __init__(self, driver):
        self.driver = driver

    def crawl(self, param, download_file):
        param = param.lower()
        links = self.driver.find_elements(By.TAG_NAME, "a")
        for link in links:
            href = link.get_attribute("href")
            text = link.text.lower()
            if param in text and href:
                print(f"[Keyword] Found: {href}")
                download_file(href)
                break
_________________________________________________________________
import os
import time
import requests
from selenium import webdriver

from xpath import XPathCrawler
from extension import ExtensionCrawler
from keyword import KeywordCrawler


class BaseCrawler:
    def __init__(self, url, download_dir="downloads"):
        self.url = url
        self.download_dir = os.path.abspath(download_dir)
        os.makedirs(self.download_dir, exist_ok=True)

        options = webdriver.ChromeOptions()
        options.add_argument("--headless")
        self.driver = webdriver.Chrome(options=options)
        self.driver.get(self.url)
        time.sleep(3)

    def download_file(self, href):
        try:
            filename = os.path.join(self.download_dir, href.split("/")[-1])
            response = requests.get(href)
            with open(filename, "wb") as f:
                f.write(response.content)
            print(f"[Download] Saved to: {filename}")
        except Exception as e:
            print(f"[Download] Failed: {e}")

    def run(self, mode, param):
        try:
            if mode == "xpath":
                crawler = XPathCrawler(self.driver)
            elif mode == "extension":
                crawler = ExtensionCrawler(self.driver)
            elif mode == "keyword":
                crawler = KeywordCrawler(self.driver)
            else:
                print("Invalid mode. Use 'xpath', 'extension', or 'keyword'")
                return

            crawler.crawl(param, self.download_file)
        finally:
            self.driver.quit()


# Example usage
if __name__ == "__main__":
    # Replace these with actual input or use argparse
    mode = "keyword"  # 'xpath' | 'extension' | 'keyword'
    url = "https://example.com"
    param = "2024 annual report"  # or XPath, or ".pdf"

    base = BaseCrawler(url)
    base.run(mode, param)
__________________________________________________________________________
